---
title: "The prediction of the way of exercises"
author: "AuthorNotShown"
date: "December 22, 2015"
output: html_document
---
###Abstract


In this study, whether people are doing exercise in the correct way is predicted based on the collected sensor data during the weight lifting exercises. After tuing the sporting vector machine model, an ovrall accuracy of >99% is achieved.


###Read data and clean data


The data is first read into R and all the variables which have missing values in more than half of the observations are skipped in teh modelling.Also, the time stamps in the dataset is also skipped. The new data is saved in variable "hdata".


```{r}
fdata<- read.csv("pml-training.csv",na.strings=c("NA","NaN", " ",""))
p<- sapply(fdata,function(x) sum(is.na(x)))
gdata<- fdata[,p<dim(fdata)[1]/2]
hdata<- gdata[,-c(1:5)]
```


###Data partitioning


10% of the data is randomly selected for final testing of the model, saved in "testing" variable. For the remaining 90% of the data, 20% are randomly sampled for model validation process, saved in variable "validationData". The remaining 80% of the data is used for training, saved in variable "training".


```{r}
library(caret)
library(e1071)
inTrain<- createDataPartition(y=hdata$classe,p=0.9,list=FALSE)
testing<- hdata[-inTrain,]
totaltraining<- hdata[inTrain,]
inTrain2<- createDataPartition(totaltraining$classe,p=0.8,list=FALSE)
training<- totaltraining[inTrain2,]
validationData<- totaltraining[-inTrain2,]

```



###Initial Modelling


A "linear discrimation analsyis" (lda) model is performed to predict the response "classe" variable in the training data set, using all other variables.


```{r}
mlda<- train(classe~.,data=training,method="lda")
confusionMatrix(predict(mlda,validationData),validationData$classe)
```


Unfortunately, the overall accuracy is not so good, around 70% for the validation dataset. This indicates the data may not be linear. Therefore, a "supporting vector machine" (svm) model is then applied to predict the response "classe" with all other variables int eh data set. The overall accuray has improved to around 95% for the validation data set.


```{r}
msvm<- svm(classe~.,data=training)
confusionMatrix(predict(msvm,validationData),validationData$classe)
```


###The selection of parameters


For SVM model, the most important parameteris the cost. Therefore, several SVM models with different cost values are modelled using cross-validation in the training data set.


```{r}
obj<- tune.svm(classe~.,data=training,cost=c(1,10,100,500,1000))
print(obj)
plot(obj)
confusionMatrix(predict(obj$best.model,validationData),validationData$classe)
```


From the result, it can be seen the best result coming from with a cost value of 500, shown in the graph above. The test accuracy is >99.5% for the validation data set, which is satisfacotary.


###The "out-of-sample" error in the testing dataset


```{r}
confusionMatrix(predict(obj$best.model,testing),testing$classe)
```


From the result, it can be seen that the test accuracy is still >99%.